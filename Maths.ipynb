{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $\\tilde{x}$ une fonction qui vérifie $\\dot{\\tilde{x}}(s) = f(s, \\tilde{x}(s))$ et telle que $\\tilde{x}(t_{j}) = x^{j}$.\n",
    "\n",
    "On pose $\\lVert e^{j+1}\\rVert = \\tilde{x}(t_{j+1}) - x^{j+1} = (x^{j} + \\int_{t_{j}}^{t_{j+1}} f(s, \\tilde{x}(s)) ds)) - x^{j+1}$\n",
    "\n",
    "Supposons que $f$ est $C^{1}$. Montrons que pour un schéma d'Euler explicite, $e^{j+1} = \\Delta t_{j}  \\frac{\\lVert f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j}) \\rVert}{2} + o(\\Delta t^{2}_{j})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait un développement limité de $\\tilde{x}$ à l'ordre 2 au point $t_{j}$, qu'on évalue en $t_{j+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tilde{x}(t_{j+1}) = x^{j} + (t_{j+1} - t_{j})f(t_{j}, \\tilde{x}(t_{j})) + \\frac{(t_{j+1} - t_{j})^{2}}{2} (\\delta_{t}(t_{j}, \\tilde{x}(t_{j})) + f(t_{j}, \\tilde{x}(t_{j}))\\delta_{x}(t_{j}, \\tilde{x}(t_{j}))) + o((t_{j+1} - t_{j})^{2})$\n",
    "\n",
    "$\\tilde{x}(t_{j+1}) = x^{j} + \\Delta t_{j}f(t_{j}, x^{j}) + \\frac{\\Delta t_{j}^{2}}{2} (\\delta_{t}(t_{j}, x^{j}) + f(t_{j}, x^{j})\\delta_{x}(t_{j}, x^{j})) + o(\\Delta t_{j}^{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on effectue un développement limité à l'ordre 1 de $x \\longmapsto f(t_{j+1}, x)$ au point $x^{j}$, évalué en $x^{j+1}$.\n",
    "\n",
    "$f(t_{j+1}, x^{j+1}) = f(t_{j+1}, x^{j}) + (x^{j+1} - x^{j})\\delta_{x}f(t_{j}, x^{j}) + o(x^{j+1} - x^{j})$\n",
    "\n",
    "On considère un schéma d'Euler explicite donc $x^{j+1} = x^{j} + \\Delta t_{j} f(t_{j}, x^{j}) $ \n",
    "\n",
    "De plus $f$ est $C^{1}$ sur un compact donc elle est bornée et atteint ses bornes, d'où :\n",
    "\n",
    "$f(t_{j+1}, x^{j+1}) = f(t_{j+1}, x^{j}) + \\Delta t_{j} f(t_{j}, x^{j})\\delta_{x}f(t_{j}, x^{j}) + o(\\Delta t_{j})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi $ e^{j+1} = \\Delta t_{j}  \\frac{f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j})}{2} + o(\\Delta t^{2}_{j})$\n",
    "\n",
    "On note $o(\\Delta t^{2}_{j}) = |\\Delta t_{j}|^2 \\epsilon(\\Delta t_{j})$ où $t \\longmapsto \\epsilon(t)$ est une fonction telle que $\\epsilon(t) \\rightarrow 0$ quand $t \\rightarrow 0$\n",
    "\n",
    "$\\lVert e^{j+1} \\lVert \\ = \\ \\lVert \\Delta t_{j}  \\frac{f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j})}{2} + \\Delta t_{j}^2 \\epsilon(\\Delta t_{j})) \\lVert \\ \\le \\ \\Delta t_{j} \\lVert \\frac{f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j})}{2}\\lVert + \\Delta t_{j}^2 \\lVert \\epsilon(\\Delta t_{j})) \\lVert$\n",
    "\n",
    "donc $\\lVert e^{j+1} \\lVert - \\Delta t_{j} \\frac{\\lVert f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j}) \\lVert}{2} \\ \\le \\ |\\Delta t_{j}|^2 \\lVert \\epsilon(\\Delta t_{j})) \\lVert$\n",
    "\n",
    "donc $\\lVert e^{j+1} \\lVert - \\Delta t_{j} \\frac{\\lVert f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j}) \\lVert}{2} \\ = \\ o(\\Delta t_{j}^2)$\n",
    "\n",
    "D'où le résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par ailleurs $f$ est $C^{1}$ sur un compact (qu'on note J) donc par l'inégalité des accroissements finis, il existe $M > 0$ tel que pour tout $t, s \\in \\mathbf{R}, x, y \\in J$, $\\lVert f(t, x) - f(s, y) \\lVert \\le M max(|t-s|, \\lVert x - y \\lVert  )$. \n",
    "\n",
    "Donc $\\lVert f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j}) \\lVert \\le M \\Delta t_{j}$ ou $ \\lVert x^{j+1} - x^{j} \\lVert$. Dans tous les cas $\\lVert f(t_{j+1}, x^{j+1}) - f(t_{j}, x^{j})\\lVert $  est un $O(\\Delta t_{j})$ car $\\Vert x^{j+1} - x^{j} \\lVert = \\Delta t_{j} f(t_{j}, x^{j})\\ $ où $\\ f(t_{j}, x^{j})$ ne dépend pas de $\\Delta t_{j}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi $\\lVert e^{j+1} \\lVert = O(\\Delta t_{j}^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons adapter le pas de temps de manière à ce que l'erreur entre la solution approchée et la solution réelle ne dépasse pas $Tol_{abs}$. Cette erreur est représentée par $\\lVert e^{j+1} \\lVert$ que l'on peut approximer grâce à la question 2. Si le pas que l'on a est suffisamment petit pour que l'erreur soit inférieure à $Tol_{abs}$, on peut l'augmenter de manière à améliorer le temps de calcul. Si au contraire l'erreur est supérieure à notre tolérance il faut diminuer le pas. De plus la relation ci-dessus nous indique que si l'on veut diviser l'erreur d'un facteur $n$, en ordre de grandeur il faut diviser le pas par $\\sqrt{n}$. \n",
    "\n",
    "Une possible stratégie d'adaptation consiste alors à prendre comme pas $\\Delta t_{j+1} = \\Delta t_{j} \\sqrt{\\frac{Tol_ {abs}}{\\lVert e^{j+1} \\lVert}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
